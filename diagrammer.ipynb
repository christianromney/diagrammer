{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a763a056-399e-45f2-912d-16607cc50735",
   "metadata": {},
   "source": [
    "## Import Classes from Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f9ba0a-e03b-44bc-b40c-3906165f74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ec7abe-0fb6-4ec3-a9c8-b716f74fe5e8",
   "metadata": {},
   "source": [
    "## Read Tangled Prompt and Spec from org-mode export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea736df-4dd4-4c32-b4b6-d9e9fd15811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = open(\"formatter-prompt.txt\", \"r\")\n",
    "description = open(\"description.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22efd733-16eb-417e-8703-87ac8ccbc862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['description'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a text formatting assistant that converts a plain text descriptions of a software application\\'s data flow into a bulleted interaction list detailing each and every data transfer implied by the description. Each line in the output list should correspond to one leg of the data flow in the form \"- <sender> sends <payload> (<format>) to <recipient>\", where <sender>, <payload>, <format>, and <recipient> are placeholders for the corresponding items from the plain text description you were given. The payload <format> is optional, and if it is not specified it should be omitted from the list.  For example, if given a description that says, \"The user sends a JSON query to the service, the service reads the file location from the database, and the service responds to the user with a PNG image\", you should produce a bulleted list with the following three lines:\\n- user sends query (JSON) to service\\n- database sends file location to service\\n- service sends image (PNG) to user\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], template='Convert the following data flow description to an interaction list: {description}'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "spec_prompt =  ChatPromptTemplate.from_messages([\n",
    "  (\"system\", format_instructions.read()),\n",
    "  (\"user\", \"Convert the following data flow description to an interaction list: {description}\")\n",
    "])\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d04a0-578a-43c6-827f-7f5d42a2f95d",
   "metadata": {},
   "source": [
    "## Invoke the LLM Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65f9830f-0cdf-4a1d-b290-a995b25a5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_chain = spec_prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533146fb-9766-42a5-a6e6-54940b96a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =  spec_chain.invoke({\"description\": description.read()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86159aaa-54f5-4a53-953d-65a36d7a6bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- user sends diagram description (plain text) to orchestrator service\n",
      "- orchestrator service sends prompt (plain text) to formatter LLM\n",
      "- formatter LLM sends list of interactions (bulleted) to orchestrator service\n",
      "- orchestrator service sends interaction list to diagrammer LLM\n",
      "- diagrammer LLM sends diagram source code to orchestrator service\n",
      "- orchestrator service sends diagram source code to diagramming tool\n",
      "- diagramming tool sends diagram image (PNG) to orchestrator service\n",
      "- orchestrator service sends diagram image (PNG) to user\n"
     ]
    }
   ],
   "source": [
    "print(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0226c4c4-00a5-4c95-ac0d-621338b99eed",
   "metadata": {},
   "source": [
    "## Diagram Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df9ed8d0-5453-48e3-ad42-6ba2b9d68754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['spec'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a software architect\\'s Data Flow Diagramming assistant that produces\\ndiagram source code in the Dot language for Graphviz from a data flow\\nspecification given as a bulleted list.\\n\\nInterpreting the Input: Each line of the input specification you receive\\ndescribes an interaction which you will convert to Dot language instructions to\\ndepict the data flow from one node to another. The input is in the form \"-\\n<sender> sends <payload> (<format>) to <recipient>\", where <sender> and\\n<recipient> are placeholders for nodes, and the <payload> and optional\\n(<format>) describe the data that is sent between them.\\n\\nProducing the Output: Terminate every Dot statement with a semicolon and use the\\nfollowing rules when generating the diagram.\\n\\nDiagram Styles:\\n- the diagram\\'s background should always be white\\n- the diagram should always use the \"Roboto Mono\" font\\n\\nNode Shapes for <senders> and <recipients>:\\n- use a box as the default node shape\\n- use a note shape for documents\\n- use a cylinder shape for databases\\n- use an oval shape for the user\\n\\nNode Styles:\\n- the colorscheme attribute should be \"paired12\" for all nodes\\n- only specify the colorscheme once (as an attribute of node) so it applies to all node shapes\\n- each individual node should reference the ordinal colors in its color attributes\\n- all nodes should have a filled style\\n- each type of architectural element (process, queue, database, document) should\\nhave a distinct color\\n- all instances of the same element type should use the same, consistent color\\n- node text should be the actual text given for the <sender> or <recipient> placeholders\\n\\nEdge Styles:\\n- edges should be labeled with the <format> and (<payload>) if given\\n- arrows should always point toward the <recipient>\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['spec'], template='Diagram the following data flow: {spec}'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagram_instructions = open(\"diagrammer-prompt.txt\", \"r\")\n",
    "diagram_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", diagram_instructions.read()),\n",
    "  (\"user\", \"Diagram the following data flow: {spec}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa5084a-a49c-4721-86c3-88933705d31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['spec'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a software architect\\'s Data Flow Diagramming assistant that produces\\ndiagram source code in the Dot language for Graphviz from a data flow\\nspecification given as a bulleted list.\\n\\nInterpreting the Input: Each line of the input specification you receive\\ndescribes an interaction which you will convert to Dot language instructions to\\ndepict the data flow from one node to another. The input is in the form \"-\\n<sender> sends <payload> (<format>) to <recipient>\", where <sender> and\\n<recipient> are placeholders for nodes, and the <payload> and optional\\n(<format>) describe the data that is sent between them.\\n\\nProducing the Output: Terminate every Dot statement with a semicolon and use the\\nfollowing rules when generating the diagram.\\n\\nDiagram Styles:\\n- the diagram\\'s background should always be white\\n- the diagram should always use the \"Roboto Mono\" font\\n\\nNode Shapes for <senders> and <recipients>:\\n- use a box as the default node shape\\n- use a note shape for documents\\n- use a cylinder shape for databases\\n- use an oval shape for the user\\n\\nNode Styles:\\n- the colorscheme attribute should be \"paired12\" for all nodes\\n- only specify the colorscheme once (as an attribute of node) so it applies to all node shapes\\n- each individual node should reference the ordinal colors in its color attributes\\n- all nodes should have a filled style\\n- each type of architectural element (process, queue, database, document) should\\nhave a distinct color\\n- all instances of the same element type should use the same, consistent color\\n- node text should be the actual text given for the <sender> or <recipient> placeholders\\n\\nEdge Styles:\\n- edges should be labeled with the <format> and (<payload>) if given\\n- arrows should always point toward the <recipient>\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['spec'], template='Diagram the following data flow: {spec}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10c8e5890>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x109462150>, model_name='gpt-4-turbo-preview', openai_api_key='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', openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagram_chain = diagram_prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8760ec0d-65c1-4563-8371-75b7f13ee889",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram_source = diagram_chain.invoke({\"spec\": spec})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a8fdbb-56a8-440a-be50-9231c472fc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```dot\n",
      "digraph DataFlow {\n",
      "    graph [bgcolor=white];\n",
      "    node [fontname=\"Roboto Mono\", colorscheme=paired12, style=filled];\n",
      "\n",
      "    user [shape=oval, color=1, label=\"user\"];\n",
      "    orchestrator_service [shape=box, color=2, label=\"orchestrator service\"];\n",
      "    formatter_LLM [shape=box, color=3, label=\"formatter LLM\"];\n",
      "    diagrammer_LLM [shape=box, color=4, label=\"diagrammer LLM\"];\n",
      "    diagramming_tool [shape=box, color=5, label=\"diagramming tool\"];\n",
      "\n",
      "    user -> orchestrator_service [label=\"plain text (diagram description)\"];\n",
      "    orchestrator_service -> formatter_LLM [label=\"plain text (prompt)\"];\n",
      "    formatter_LLM -> orchestrator_service [label=\"bulleted (list of interactions)\"];\n",
      "    orchestrator_service -> diagrammer_LLM [label=\"interaction list\"];\n",
      "    diagrammer_LLM -> orchestrator_service [label=\"diagram source code\"];\n",
      "    orchestrator_service -> diagramming_tool [label=\"diagram source code\"];\n",
      "    diagramming_tool -> orchestrator_service [label=\"PNG (diagram image)\"];\n",
      "    orchestrator_service -> user [label=\"PNG (diagram image)\"];\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(diagram_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca981484-2081-428b-b261-df87e85e1628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
