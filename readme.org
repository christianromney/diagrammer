* Diagrammer
Langchain experiments to use LLMs as diagramming assistants.

** Enivronment Setup
*** Prerequisites
- [[https://direnv.net/][direnv]] ~brew install direnv~
- [[https://docs.conda.io/projects/miniconda/en/latest/][miniconda]] ~brew install --cask miniconda~
*** Global Configuration
**** direnv layout support
#+begin_src shell :file ~/.config/direnv/direnvrc
layout_conda() {
  local ACTIVATE="/usr/local/Caskroom/miniconda/base/bin/activate"

  if [ -n "$1" ]; then
    # Explicit environment name from layout command.
    local env_name="$1"
    source $ACTIVATE ${env_name}
  elif (grep -q name: environment.yml); then
    # Detect environment name from `environment.yml` file in `.envrc` directory
    source $ACTIVATE `grep name: environment.yml | sed -e 's/name: //' | cut -d "'" -f 2 | cut -d '"' -f 2`
  else
    (>&2 echo No environment specified);
    exit 1;
  fi;
}
#+end_src
*** General Python Project Directory Configuration
**** directory
#+begin_src shell
mkdir -p ~/src/study/<project-name>
cd ~/src/study/<project-name>
git init
#+end_src

**** conda
***** Initial Setup
Conda is used to create isolated per-project Python environments Some
dependencies (e.g. jupyter) are installed via conda, for most others you can
just use pip once the relevant conda environment is activated.

#+begin_src shell
conda create --name <project-name> jupyter
#+end_src
***** Maintenance
Conda's base installation should be updated from time to time.
#+begin_src shell
conda update -n base -c defaults conda
#+end_src
**** direnv
direnv is used to set project-specific environment variables. The layout
capability also gives the ability to automatically activate language-specific
toolchains per directory.

#+begin_src shell :file .envrc
export OPENAI_API_KEY=<api-key>
layout conda <project-name>
#+end_src

Once the we permit direnv to auto-load the directory's .envrc, it will also automatically activate conda whenever we `cd` into the directory at the terminal.

#+begin_src shell
direnv allow
#+end_src

*** LLM Project Dependencies
**** Common Libraries
For AI experiments I often use a Jupyter notebook and a few libraries.
- [[https://www.langchain.com/][LangChain]] :: the defacto framework for developing applications powered by language models
- [[https://python.langchain.com/docs/langgraph][LangGraph]] :: LangGraph is a library for building stateful, multi-actor applications with LLMs
- [[https://www.langflow.org/][LangFlow]] :: an easy way to prototype LangChain flows
- [[https://docs.crewai.com/][CrewAI]] :: framework for orchestrating role-playing, autonomous AI agents
- [[https://docs.trychroma.com/][ChromaDB]] :: open-source embedding database
- [[https://weaviate.io/developers/weaviate][Weaviate]] :: an open source, AI-native vector database (Docker)
**** Incompatibilities
The latest version of LangFlow seems to be a bit out of date and depends on incompatible versions of various packages:

| Langflow Dependency | Conflicts With   |
|---------------------+------------------|
| openai              | langchain-openai |
| langchain           | crewai           |


**** Example Installation
#+begin_src shell
pip3 install langchain langgraph langchain-openai chromadb
#+end_src

*** Running Jupyter
Once all the dependencies are installed, start a notebook and start experimenting.

#+begin_src shell
jupyter lab
#+end_src

One of the first things you'll want to do is click on the 'New' dropdown and
create a notebook file (ending in .ipnyb) and give it a title.

** Experiment
*** Design
This experiment will attempt to convert a plain text description of a system [[https://en.wikipedia.org/wiki/Data-flow_diagram][Data Flow]] into a PNG diagram that visualizes that data flow. We will break the computation up into 3 steps:
1. converting the natural language description into a succinct bulleted list (specification)
2. transforming that specification into [[https://graphviz.org/doc/info/lang.html][Dot language]] source code
3. generating a PNG diagram from the Dot source code using [[https://graphviz.org/][Graphviz]]
*** Source Code
The [[file:diagrammer.ipynb][source code]] for this experiment lives in a [[https://jupyter.org/][Jupyter]] (Python) notebook using
the LangChain framework.

*** System Description
The text below specifies both the architecture of this experiment and serves as a convenient test input to the application.
#+begin_src text :tangle description.txt
A user submits a plain text diagram description to the orchestator. The
orchestrator adds the description to a plain text prompt which it sends to a
formatter LLM, which responds with a bulleted list of interactions called a
spec. The orchestrator sends that spec to a diagrammer llm which responds with
diagram source code. The orchestrator sends the diagram source code to the
digramming tool which responds with a PNG diagram image. Finally, the
orchestrator returns the diagram image to the user.
#+end_src
*** Formatter Prompt

#+begin_src text :tangle formatter-prompt.txt
You are a text formatting assistant that converts a plain text descriptions of a
software application's data flow into a bulleted interaction list detailing each
and every data transfer implied by the description. Each line in the output list
should correspond to one leg of the data flow in the form "- <sender> sends
<payload> (<format>) to <recipient>", where <sender>, <payload>, <format>, and
<recipient> are placeholders for the corresponding items from the plain text
description you were given. The payload <format> is optional, and if it is not
specified it should be omitted from the list.

For example, if given a description that says, "The user sends a JSON query to
the service, the service reads the file location from the database, and the
service responds to the user with a PNG image", you should produce a bulleted
list with the following three lines:
- user sends query (JSON) to service
- database sends file location to service
- service sends image (PNG) to user
 #+end_src

*** Formatter Output
This is the output from one sample run:

#+begin_src text :tangle formatter-output.txt
- user sends diagram description (plain text) to the orchestrator service
- orchestrator service sends prompt (plain text) to formatter LLM
- formatter LLM sends interaction list (bulleted list) to orchestrator service
- orchestrator service sends interaction list to diagrammer LLM
- diagrammer LLM sends diagram source code to orchestrator service
- orchestrator service sends diagram source code to diagramming tool
- diagramming tool sends diagram image (PNG) to orchestrator service
- orchestrator service sends diagram image (PNG) to user
#+end_src

*** Diagrammer Prompt
#+begin_src text :tangle diagrammer-prompt.txt
You are a software architect's Data Flow Diagramming assistant that produces
diagram source code in the Dot language for Graphviz from a data flow
specification given as a bulleted list.

Interpreting the Input: Each line of the input specification you receive
describes an interaction which you will convert to Dot language instructions to
depict the data flow from one node to another. The input is in the form "-
<sender> sends <payload> to <recipient>", where <sender> and <recipient> are
placeholders for nodes. Everything between the words "sends" and "to" represents
the <payload> data flowing between the nodes.

Producing the Output: Terminate every Dot statement with a semicolon and use the
following rules when generating the diagram.

Diagram Styles:
- the diagram's background should always be white
- the diagram should always use the "Roboto Mono" font
- only specify the colorscheme once so it applies to the entire diagram
- the colorscheme should be "paired12"

Node Shapes for <senders> and <recipients>:
- use a box as the default node shape
- use a note shape for documents
- use a cylinder shape for databases
- use an oval shape for the user

Node Styles:
- each individual node should reference the ordinal colors in its color attributes
- all nodes should have a filled style
- each type of architectural element (process, queue, database, document) should
have a distinct color
- all instances of the same element type should use the same, consistent color
- node text should be the actual text given for the <sender> or <recipient> placeholders

Edge Styles:
- edges should be labeled with the <payload> text
- arrows should always point toward the <recipient>
- if 2 nodes share multiple edges, they should be colored distinctly
- the color and fontcolor of an edge must always match
- use newlines to break long labels
#+end_src

*** Diagrammer Output
#+begin_src dot :file diagram.png :tangle diagram.dot :cmdline -Kdot -Tpng
digraph DataFlow {
    graph [bgcolor=white, fontname="Roboto Mono"];
    node [colorscheme=paired12, style=filled, fontname="Roboto Mono"];
    edge [colorscheme=paired12, fontname="Roboto Mono"];

    // Nodes
    user [shape=oval, color=1, label="user"];
    orchestrator [shape=box, color=2, label="orchestrator"];
    formatter_LLM [shape=box, color=3, label="formatter LLM"];
    diagrammer_LLM [shape=box, color=3, label="diagrammer LLM"];
    diagramming_tool [shape=box, color=3, label="diagramming tool"];

    // Edges
    user -> orchestrator [label="diagram description\n(plain text)", color=1, fontcolor=1];
    orchestrator -> formatter_LLM [label="prompt\n(plain text)", color=2, fontcolor=2];
    formatter_LLM -> orchestrator [label="spec\n(bulleted list)", color=3, fontcolor=3];
    orchestrator -> diagrammer_LLM [label="spec", color=4, fontcolor=4];
    diagrammer_LLM -> orchestrator [label="diagram source code", color=5, fontcolor=5];
    orchestrator -> diagramming_tool [label="diagram source code", color=6, fontcolor=6];
    diagramming_tool -> orchestrator [label="diagram image\n(PNG)", color=7, fontcolor=7];
    orchestrator -> user [label="diagram image\n(PNG)", color=8, fontcolor=8];
}
#+end_src

#+RESULTS:
[[file:diagram.png]]

*** Diagram Result
[[file:diagram.png]]

** Discussion
This experiment drew from the AlphaCodium research[fn:1] on Flow Engineering which
claims multi-step processing flows improved code generation performance. The
authors also found that using bulleted lists as LLM prompt input specifications
produced better results than plain text.

The diagram illustrated above (actual execution output) /does/ capture the intent
of the natural language system description in the specification.

*** Formatter Task
I observed consistently good results from the formatter task given to the LLM
with its relatively simple prompt.

It would be interesting to compare different degrees of structured output
formats including plain text, lists, and delimited (csv) or tagged (xml) text.

*** Diagrammer Task
Early versions of the diagrammer prompt talked about the <payload> and the
optional (<format>). The diagrammer task had trouble with these instructions,
often confusing the instructions for the <payload> and the <format>.

I eventually realized those details were only the concern of the formatter and
that the diagrammer could just treat all the text between the nodes as a
black-box payload label.

An alternative to having an LLM generate the diagram source code from the spec
would be to write a small interpreter for a subset of the Dot language.

This would likely improve the predictability, fidelity, and performance of the
code generation at the expense of human effort.

** Future Work
This experiment needs some method of evaluating the results and a statistically
meaningful number of test runs over which to collect performance data.

With that in place, we could compare different tools and approaches, including:
- evaluating a broader set of inputs and outputs
- trying other fidelity-improving techniques
- using open-source local LLM
** References
[fn:1] [[https://arxiv.org/pdf/2401.08500.pdf][Ridnik, Tal, Dedy Kredo, and Itamar Friedman. “Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering.” arXiv, January 16, 2024. https://doi.org/10.48550/arXiv.2401.08500.]]
